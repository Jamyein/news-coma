"""
Markdownç”Ÿæˆæ¨¡å—
è´Ÿè´£ç”Ÿæˆç»“æ„åŒ–Markdownæ–‡æ¡£
"""
import logging
from datetime import datetime
from typing import List, Tuple
from pathlib import Path

from src.models import NewsItem

logger = logging.getLogger(__name__)


class MarkdownGenerator:
    """Markdownç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "docs", archive_dir: str = "archive"):
        self.output_dir = Path(output_dir)
        self.archive_dir = Path(archive_dir)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.archive_dir.mkdir(parents=True, exist_ok=True)
    
    def generate(self, items: List[NewsItem], timestamp: datetime) -> Tuple[str, str]:
        """
        ç”ŸæˆMarkdownæ–‡ä»¶
        
        Args:
            items: æ–°é—»åˆ—è¡¨(å·²æ’åº)
            timestamp: ç”Ÿæˆæ—¶é—´æˆ³
            
        Returns:
            (latest_path, archive_path)
        """
        content = self._build_content(items, timestamp)
        
        # æ›´æ–°latest.md
        latest_path = self.output_dir / "latest.md"
        self._write_file(latest_path, content)
        logger.info(f"å·²æ›´æ–°: {latest_path}")
        
        # åˆ›å»ºå½’æ¡£
        archive_filename = timestamp.strftime("%Y-%m-%d") + ".md"
        archive_path = self.archive_dir / archive_filename
        
        # å¦‚æœå½’æ¡£æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿½åŠ åˆ°ç°æœ‰å†…å®¹
        if archive_path.exists():
            existing_content = archive_path.read_text(encoding='utf-8')
            # åˆå¹¶å†…å®¹(å»é‡)
            content = self._merge_archive_content(existing_content, content)
        
        self._write_file(archive_path, content)
        logger.info(f"å·²å½’æ¡£: {archive_path}")
        
        return str(latest_path), str(archive_path)
    
    def _build_content(self, items: List[NewsItem], timestamp: datetime) -> str:
        """æ„å»ºMarkdownå†…å®¹"""
        header = f"""# ğŸ“° ç§‘æŠ€æ–°é—»ç²¾é€‰

> ğŸ• æ›´æ–°æ—¶é—´: {timestamp.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")} UTC  
> ğŸ“Š æœ¬æœŸç²¾é€‰ **{len(items)}** æ¡é«˜è´¨é‡ç§‘æŠ€æ–°é—»  
> ğŸ¤– ç”± AI è‡ªåŠ¨ç­›é€‰ã€ç¿»è¯‘å’Œæ€»ç»“

---

"""
        
        if not items:
            body = "*æœ¬æœŸæš‚æ— ç¬¦åˆæ¡ä»¶çš„æ–°é—»*\n\n"
        else:
            body = ""
            for i, item in enumerate(items, 1):
                # æ ¼å¼åŒ–å…³é”®è¦ç‚¹
                key_points_str = "\n".join([f"- {point}" for point in (item.key_points or ["æš‚æ— è¦ç‚¹"])])
                
                body += f"""### {i}. {item.translated_title or item.title}

**ğŸ“Œ æ¥æº**: {item.source} | **ğŸ·ï¸ åˆ†ç±»**: {item.category} | **â­ è¯„åˆ†**: {item.ai_score or 'N/A'}/10

**ğŸ“ æ‘˜è¦**:
{item.ai_summary or 'æš‚æ— æ‘˜è¦'}

**ğŸ’¡ å…³é”®è¦ç‚¹**:
{key_points_str}

**ğŸ”— åŸæ–‡é“¾æ¥**: [{item.title}]({item.link})

---

"""
        
        # æ·»åŠ é¡µè„š
        footer = """## ğŸ“® è®¢é˜…

- **RSSè®¢é˜…**: [feed.xml](https://raw.githubusercontent.com/{username}/{repo}/main/feed.xml)
- **æ›´æ–°æ—¶é—´**: æ¯6å°æ—¶è‡ªåŠ¨æ›´æ–°
- **ç”Ÿæˆæ–¹å¼**: GitHub Actions + OpenAI GPT-4o-mini

---

*æœ¬é¡¹ç›®è‡ªåŠ¨èšåˆç§‘æŠ€æ–°é—»ï¼Œç”±AIç­›é€‰æœ€æœ‰ä»·å€¼çš„å†…å®¹*
"""
        
        return header + body + footer
    
    def _merge_archive_content(self, existing: str, new: str) -> str:
        """åˆå¹¶å½’æ¡£å†…å®¹(ç®€å•å»é‡)"""
        # å¦‚æœå†…å®¹ç›¸åŒï¼Œè¿”å›æ–°çš„
        if existing == new:
            return new
        
        # å¦åˆ™ä¿ç•™æ–°çš„(æˆ–å¯ä»¥åˆå¹¶é€»è¾‘)
        return new
    
    def _write_file(self, path: Path, content: str):
        """å†™å…¥æ–‡ä»¶"""
        try:
            path.write_text(content, encoding='utf-8')
        except Exception as e:
            logger.error(f"å†™å…¥æ–‡ä»¶å¤±è´¥ {path}: {e}")
            raise
