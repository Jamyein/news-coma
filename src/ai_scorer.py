"""
AIè¯„åˆ†æ¨¡å—
è´Ÿè´£ä½¿ç”¨OpenAI APIå¯¹æ–°é—»è¿›è¡Œè¯„åˆ†ã€ç¿»è¯‘å’Œæ€»ç»“
æ”¯æŒ14å®¶å›½å†…å¤–LLMæä¾›å•†ï¼Œè‡ªåŠ¨å›é€€
"""
import json
import logging
import asyncio
import time
from typing import List, Dict

from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential

from src.models import NewsItem, AIConfig, ProviderConfig, FallbackConfig

logger = logging.getLogger(__name__)


class SimpleRateLimiter:
    """
    ç®€å•çš„å¼‚æ­¥ä»¤ç‰Œæ¡¶é€Ÿç‡é™åˆ¶å™¨
    """
    
    def __init__(self, max_requests: int = 60, time_window: float = 60.0):
        self.max_requests = max_requests
        self.time_window = time_window
        self.tokens = float(max_requests)
        self.last_update = time.time()
        self.lock = asyncio.Lock()
    
    async def acquire(self, timeout: float = 120.0):
        """è·å–ä¸€ä¸ªä»¤ç‰Œï¼Œå¿…è¦æ—¶ç­‰å¾…"""
        async with self.lock:
            start_time = time.time()
            
            while self.tokens < 1:
                now = time.time()
                elapsed = now - self.last_update
                
                # è¡¥å……ä»¤ç‰Œ
                self.tokens = min(
                    float(self.max_requests),
                    self.tokens + elapsed * (self.max_requests / self.time_window)
                )
                self.last_update = now
                
                if self.tokens < 1:
                    # éœ€è¦ç­‰å¾…
                    wait_time = self.time_window / self.max_requests
                    
                    if time.time() - start_time + wait_time > timeout:
                        raise TimeoutError(f"é€Ÿç‡é™åˆ¶ç­‰å¾…è¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼‰")
                    
                    # çŸ­æš‚é‡Šæ”¾é”è®©å…¶ä»–ä»»åŠ¡æœ‰æœºä¼šæ‰§è¡Œ
                    self.lock.release()
                    try:
                        await asyncio.sleep(wait_time)
                    finally:
                        await self.lock.acquire()
            
            self.tokens -= 1
            self.last_update = time.time()


class AIScorer:
    """AIæ–°é—»è¯„åˆ†å™¨ - æ”¯æŒ14å®¶LLMæä¾›å•†å’Œè‡ªåŠ¨å›é€€"""
    
    def __init__(self, config: AIConfig):
        self.config = config
        self.fallback = config.fallback
        self.current_provider_name = config.provider
        self.providers_config = config.providers_config
        self.criteria = config.scoring_criteria
        
        # åˆå§‹åŒ–ä¸»æä¾›å•†
        self._init_provider(self.current_provider_name)
    
    def _init_provider(self, provider_name: str):
        """åˆå§‹åŒ–æŒ‡å®šæä¾›å•†"""
        if provider_name not in self.providers_config:
            raise ValueError(f"æœªçŸ¥çš„æä¾›å•†: {provider_name}")
        
        provider_config = self.providers_config[provider_name]
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        self.client = AsyncOpenAI(
            api_key=provider_config.api_key,
            base_url=provider_config.base_url
        )
        self.model = provider_config.model
        self.current_provider_name = provider_name
        self.current_config = provider_config
        
        # åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
        if provider_config.rate_limit_rpm:
            self.rate_limiter = SimpleRateLimiter(
                max_requests=provider_config.rate_limit_rpm
            )
            logger.info(f"[{provider_name}] å¯ç”¨é€Ÿç‡é™åˆ¶: {provider_config.rate_limit_rpm} RPM")
        else:
            self.rate_limiter = None
        
        logger.info(f"åˆå§‹åŒ–AIæä¾›å•†: {provider_name} ({self.model})")
    
    async def score_all(self, items: List[NewsItem]) -> List[NewsItem]:
        """
        æ‰¹é‡è¯„åˆ†æ‰€æœ‰æ–°é—»ï¼Œæ”¯æŒè‡ªåŠ¨å›é€€
        """
        if not self.fallback.enabled:
            # ä¸å›é€€ï¼Œç›´æ¥ä½¿ç”¨å½“å‰æä¾›å•†
            return await self._score_with_provider(items, self.current_provider_name)
        
        # æ„å»ºå›é€€é“¾
        fallback_chain = self._build_fallback_chain()
        last_exception = None
        
        for provider_name in fallback_chain:
            try:
                logger.info(f"ğŸ”„ å°è¯•ä½¿ç”¨æä¾›å•†: {provider_name}")
                
                # ä¸´æ—¶åˆ‡æ¢åˆ°è¯¥æä¾›å•†
                self._init_provider(provider_name)
                
                # æ‰§è¡Œè¯„åˆ†
                results = await self._score_with_provider(items, provider_name)
                
                logger.info(f"âœ… æä¾›å•† {provider_name} è°ƒç”¨æˆåŠŸ")
                return results
                
            except Exception as e:
                logger.error(f"âŒ æä¾›å•† {provider_name} å¤±è´¥: {e}")
                last_exception = e
                continue
        
        # æ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥
        logger.error("âŒ æ‰€æœ‰AIæä¾›å•†å‡å¤±è´¥ï¼Œæ— æ³•å®Œæˆè¯„åˆ†")
        raise last_exception
    
    def _build_fallback_chain(self) -> List[str]:
        """æ„å»ºå›é€€é“¾ï¼ˆå»é‡ï¼‰"""
        chain = []
        seen = set()
        
        # 1. é¦–é€‰å½“å‰é…ç½®çš„ä¸»æä¾›å•†
        if self.current_provider_name and self.current_provider_name in self.providers_config:
            chain.append(self.current_provider_name)
            seen.add(self.current_provider_name)
        
        # 2. æ·»åŠ fallback_chainä¸­é…ç½®çš„æä¾›å•†
        for provider in self.fallback.fallback_chain:
            if provider not in seen and provider in self.providers_config:
                chain.append(provider)
                seen.add(provider)
        
        return chain
    
    async def _score_with_provider(self, items: List[NewsItem], provider_name: str) -> List[NewsItem]:
        """ä½¿ç”¨æŒ‡å®šæä¾›å•†è¯„åˆ†"""
        provider_config = self.providers_config[provider_name]
        
        # ä½¿ç”¨å½“å‰æä¾›å•†çš„é…ç½®
        semaphore = asyncio.Semaphore(provider_config.max_concurrent)
        batch_size = provider_config.batch_size
        
        # åˆ†æ‰¹å¤„ç†
        batches = [
            items[i:i+batch_size] 
            for i in range(0, len(items), batch_size)
        ]
        
        all_results = []
        
        for batch_idx, batch in enumerate(batches):
            logger.info(
                f"[{provider_name}] å¤„ç†ç¬¬ {batch_idx+1}/{len(batches)} æ‰¹, "
                f"å…± {len(batch)} æ¡"
            )
            
            tasks = []
            for item in batch:
                task = self._score_single_with_semaphore(semaphore, item, provider_config)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for item, result in zip(batch, results):
                if isinstance(result, Exception):
                    logger.error(
                        f"[{provider_name}] è¯„åˆ†å¤±è´¥: {item.title[:50]}... "
                        f"é”™è¯¯: {result}"
                    )
                    item.ai_score = 5.0
                    item.translated_title = item.title
                    item.ai_summary = "è¯„åˆ†å¤±è´¥"
                    item.key_points = []
                    all_results.append(item)
                else:
                    all_results.append(result)
        
        return all_results
    
    async def _score_single_with_semaphore(
        self, 
        semaphore: asyncio.Semaphore, 
        item: NewsItem,
        provider_config: ProviderConfig
    ) -> NewsItem:
        """ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘"""
        async with semaphore:
            return await self._score_single(item, provider_config)
    
    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=5),
        reraise=True
    )
    async def _score_single(self, item: NewsItem, provider_config: ProviderConfig) -> NewsItem:
        """å•æ¡æ–°é—»è¯„åˆ†"""
        # åº”ç”¨é€Ÿç‡é™åˆ¶
        if self.rate_limiter:
            await self.rate_limiter.acquire()
        
        prompt = self._build_prompt(item)
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±ç§‘æŠ€æ–°é—»ç¼–è¾‘ï¼Œæ“…é•¿è¯„ä¼°æ–°é—»ä»·å€¼å’Œæ’°å†™ä¸­æ–‡æ‘˜è¦ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=provider_config.max_tokens,
                temperature=provider_config.temperature,
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            return self._parse_response(item, content)
            
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¤±è´¥ ({self.current_provider_name}): {e}")
            raise
    
    def _build_prompt(self, item: NewsItem) -> str:
        """æ„å»ºè¯„åˆ†Prompt"""
        criteria_desc = []
        for key, weight in self.criteria.items():
            desc = {
                'importance': 'é‡è¦æ€§(è¡Œä¸šå½±å“ã€æŠ€æœ¯çªç ´)',
                'timeliness': 'æ—¶æ•ˆæ€§(æ–°é—»æ–°é²œåº¦)',
                'technical_depth': 'æŠ€æœ¯æ·±åº¦(ä¸“ä¸šæ€§å’Œæ·±åº¦)',
                'audience_breadth': 'å—ä¼—å¹¿åº¦(å½±å“èŒƒå›´)',
                'practicality': 'å®ç”¨æ€§(å¯¹å¼€å‘è€…ä»·å€¼)'
            }.get(key, key)
            criteria_desc.append(f"- {desc}: {int(weight*100)}%")
        
        return f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±ç§‘æŠ€æ–°é—»ç¼–è¾‘ã€‚è¯·å¯¹ä»¥ä¸‹æ–°é—»è¿›è¡Œè¯„åˆ†å’Œåˆ†æã€‚

è¯„åˆ†ç»´åº¦ï¼ˆ1-10åˆ†åˆ¶ï¼‰ï¼š
{chr(10).join(criteria_desc)}

æ–°é—»ä¿¡æ¯ï¼š
æ ‡é¢˜: {item.title}
æ¥æº: {item.source}
åˆ†ç±»: {item.category}
å‘å¸ƒæ—¶é—´: {item.published_at.strftime('%Y-%m-%d %H:%M')}
æ‘˜è¦: {item.summary[:500] if item.summary else 'N/A'}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›(ä¸è¦æ·»åŠ markdownä»£ç å—æ ‡è®°)ï¼š
{{
    "importance": 8,
    "timeliness": 9,
    "technical_depth": 7,
    "audience_breadth": 6,
    "practicality": 8,
    "total_score": 7.5,
    "chinese_title": "ç¿»è¯‘æˆä¸­æ–‡çš„æ ‡é¢˜",
    "chinese_summary": "200å­—å·¦å³çš„ä¸­æ–‡æ€»ç»“",
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
}}

æ³¨æ„ï¼š
1. total_scoreæ ¹æ®æƒé‡è‡ªåŠ¨è®¡ç®—: importanceÃ—{self.criteria.get('importance', 0.3)} + timelinessÃ—{self.criteria.get('timeliness', 0.2)} + technical_depthÃ—{self.criteria.get('technical_depth', 0.2)} + audience_breadthÃ—{self.criteria.get('audience_breadth', 0.15)} + practicalityÃ—{self.criteria.get('practicality', 0.15)}
2. chinese_titleè¦å‡†ç¡®ä¼ è¾¾åŸæ„ï¼Œé€‚åˆä¸­æ–‡è¯»è€…
3. chinese_summaryè¦çªå‡ºæ ¸å¿ƒä»·å€¼å’Œå½±å“
4. key_pointsåˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
"""
    
    def _parse_response(self, item: NewsItem, content: str) -> NewsItem:
        """è§£æAIå“åº”"""
        try:
            data = json.loads(content)
            
            # è®¡ç®—åŠ æƒæ€»åˆ†
            total_score = (
                data.get('importance', 5) * self.criteria.get('importance', 0.3) +
                data.get('timeliness', 5) * self.criteria.get('timeliness', 0.2) +
                data.get('technical_depth', 5) * self.criteria.get('technical_depth', 0.2) +
                data.get('audience_breadth', 5) * self.criteria.get('audience_breadth', 0.15) +
                data.get('practicality', 5) * self.criteria.get('practicality', 0.15)
            )
            
            item.ai_score = round(total_score, 1)
            item.translated_title = data.get('chinese_title', item.title)
            item.ai_summary = data.get('chinese_summary', '')
            item.key_points = data.get('key_points', [])
            
            return item
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {content[:200]}... é”™è¯¯: {e}")
            item.ai_score = 5.0
            item.translated_title = item.title
            item.ai_summary = "è§£æå¤±è´¥"
            item.key_points = []
            return item
        except Exception as e:
            logger.error(f"å“åº”è§£æå¤±è´¥: {e}")
            item.ai_score = 5.0
            item.translated_title = item.title
            item.ai_summary = "è§£æå¤±è´¥"
            item.key_points = []
            return item
