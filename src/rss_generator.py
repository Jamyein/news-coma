"""
RSSè®¢é˜…æ–‡ä»¶ç”Ÿæˆæ¨¡å—
è´Ÿè´£åŸºäºMarkdownæ–‡ä»¶ç”ŸæˆRSS feed.xmlæ–‡ä»¶
"""
import logging
import os
import re
from datetime import datetime
from typing import List, Dict
from xml.sax.saxutils import escape
from pathlib import Path

logger = logging.getLogger(__name__)


class RSSGenerator:
    """åŸºäºMarkdownæ–‡ä»¶çš„RSSè®¢é˜…æ–‡ä»¶ç”Ÿæˆå™¨"""
    
    def __init__(self, feed_path: str = "feed.xml", archive_dir: str = "archive", 
                 docs_dir: str = "docs", max_items: int = 50):
        self.feed_path = Path(feed_path)
        self.archive_dir = Path(archive_dir)
        self.docs_dir = Path(docs_dir)
        self.max_items = max_items
    
    def _markdown_to_html(self, markdown_text: str) -> str:
        """
        å°†Markdownæ–‡æœ¬è½¬æ¢ä¸ºHTML
        
        Args:
            markdown_text: Markdownæ ¼å¼çš„æ–‡æœ¬
            
        Returns:
            HTMLæ ¼å¼çš„æ–‡æœ¬
        """
        if not markdown_text:
            return ""
        
        html = markdown_text
        
        # 1. è½¬æ¢æ ‡é¢˜ (### â†’ <h3>)
        html = re.sub(r'^###\s+(.+?)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
        
        # 2. è½¬æ¢ç²—ä½“ (** â†’ <strong>)
        html = re.sub(r'\*\*([^*]+?)\*\*', r'<strong>\1</strong>', html)
        
        # 3. è½¬æ¢é“¾æ¥ ([æ–‡æœ¬](URL) â†’ <a>)
        def replace_link(match):
            link_text = match.group(1)
            url = match.group(2)
            return f'<a href="{url}">{link_text}</a>'
        html = re.sub(r'\[([^\]]+)\]\(([^\)]+)\)', replace_link, html)
        
        # 4. è½¬æ¢åˆ—è¡¨ (- â†’ <ul><li>)
        lines = html.split('\n')
        result_lines = []
        in_list = False
        list_items = []
        
        for line in lines:
            stripped = line.strip()
            list_match = re.match(r'^[-\*]\s+(.+)$', stripped)
            
            if list_match:
                if not in_list:
                    in_list = True
                    list_items = []
                item_text = list_match.group(1)
                list_items.append(f'<li>{item_text}</li>')
            else:
                if in_list:
                    result_lines.append('<ul>')
                    result_lines.extend(list_items)
                    result_lines.append('</ul>')
                    in_list = False
                    list_items = []
                result_lines.append(line)
        
        if in_list:
            result_lines.append('<ul>')
            result_lines.extend(list_items)
            result_lines.append('</ul>')
        
        html = '\n'.join(result_lines)
        
        # 5. è½¬æ¢åˆ†éš”çº¿ (--- â†’ <hr/>)
        html = re.sub(r'^---\s*$', '<hr/>', html, flags=re.MULTILINE)
        
        # 6. åŒ…è£¹æ®µè½
        lines = html.split('\n')
        result_lines = []
        current_para = []
        
        for line in lines:
            stripped = line.strip()
            
            if not stripped or (stripped.startswith('<') and stripped.endswith('>')):
                if current_para:
                    para_text = ' '.join(current_para)
                    if para_text:
                        result_lines.append(f'<p>{para_text}</p>')
                    current_para = []
                if stripped:
                    result_lines.append(line)
            else:
                current_para.append(stripped)
        
        if current_para:
            para_text = ' '.join(current_para)
            if para_text:
                result_lines.append(f'<p>{para_text}</p>')
        
        html = '\n'.join(result_lines)
        
        return html.strip()
    
    def generate(self) -> str:
        """
        åŸºäºMarkdownæ–‡ä»¶ç”ŸæˆRSS feed.xml
        
        Returns:
            ç”Ÿæˆçš„RSS XMLå­—ç¬¦ä¸²
        """
        # æ”¶é›†æ‰€æœ‰Markdownæ–‡ä»¶
        markdown_files = self._collect_markdown_files()
        
        # è§£ææ–‡ä»¶ä¿¡æ¯
        file_infos = []
        for file_path in markdown_files:
            try:
                file_info = self._parse_markdown_file(file_path)
                if file_info:
                    file_infos.append(file_info)
            except Exception as e:
                logger.warning(f"è§£æMarkdownæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æŒ‰æ—¥æœŸæ’åº(æœ€æ–°çš„åœ¨å‰)
        file_infos.sort(key=lambda x: x.get('date', datetime.min), reverse=True)
        
        # é™åˆ¶æ•°é‡
        file_infos = file_infos[:self.max_items]
        
        # ç”ŸæˆXML
        rss_xml = self._build_rss_xml(file_infos)
        
        # å†™å…¥æ–‡ä»¶
        self.feed_path.write_text(rss_xml, encoding='utf-8')
        logger.info(f"å·²æ›´æ–°RSS feed: {self.feed_path} ({len(file_infos)} ä¸ªæ–‡ä»¶)")
        
        return rss_xml
    
    def _collect_markdown_files(self) -> List[Path]:
        """æ”¶é›†archiveå’Œdocsç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶"""
        markdown_files = []
        
        # æ”¶é›†archiveç›®å½•ä¸­çš„æ–‡ä»¶
        if self.archive_dir.exists():
            for file_path in self.archive_dir.glob("*.md"):
                markdown_files.append(file_path)
        
        # æ”¶é›†docsç›®å½•ä¸­çš„æ–‡ä»¶(latest.md)
        if self.docs_dir.exists():
            latest_file = self.docs_dir / "latest.md"
            if latest_file.exists():
                markdown_files.append(latest_file)
        
        logger.info(f"æ‰¾åˆ° {len(markdown_files)} ä¸ªMarkdownæ–‡ä»¶")
        return markdown_files
    
    def _parse_markdown_file(self, file_path: Path) -> Dict:
        """è§£æMarkdownæ–‡ä»¶ï¼Œæå–ä¿¡æ¯"""
        if not file_path.exists():
            return None
        
        content = file_path.read_text(encoding='utf-8')
        
        # æå–æ—¥æœŸ
        date_match = None
        if file_path.name == "latest.md":
            # latest.md: ä»æ›´æ–°æ—¶é—´æå–æ—¥æœŸ
            date_match = re.search(r'æ›´æ–°æ—¶é—´:\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥', content)
        else:
            # å½’æ¡£æ–‡ä»¶: ä»æ–‡ä»¶åæå–æ—¥æœŸ (YYYY-MM-DD.md)
            date_match = re.match(r'(\d{4})-(\d{2})-(\d{2})\.md$', file_path.name)
        
        file_date = None
        if date_match:
            if file_path.name == "latest.md":
                year, month, day = int(date_match.group(1)), int(date_match.group(2)), int(date_match.group(3))
                file_date = datetime(year, month, day)
            else:
                year, month, day = int(date_match.group(1)), int(date_match.group(2)), int(date_match.group(3))
                file_date = datetime(year, month, day)
        
        # æå–æ–°é—»æ•°é‡
        news_count = 0
        count_match = re.search(r'æœ¬æœŸç²¾é€‰\s*\*\*(\d+)\*\*\s*æ¡', content)
        if count_match:
            news_count = int(count_match.group(1))
        
        # æ„å»ºæ ‡é¢˜
        if file_date:
            title = f"{file_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} æ–°é—»æ±‡æ€»"
        else:
            title = f"{file_path.stem} æ–°é—»æ±‡æ€»"
        
        # æ„å»ºé“¾æ¥
        repo_url = os.getenv('GITHUB_REPOSITORY', 'username/news')
        username, repo = repo_url.split('/') if '/' in repo_url else ('username', 'news')
        
        # å°†Windowsè·¯å¾„è½¬æ¢ä¸ºPOSIXè·¯å¾„ç”¨äºURL
        file_path_posix = str(file_path).replace('\\', '/')
        
        if file_path.name == "latest.md":
            # latest.md ä½¿ç”¨GitHub Pages URL
            link = f"https://{username}.github.io/{repo}/"
        else:
            # å½’æ¡£æ–‡ä»¶ä½¿ç”¨GitHub raw URL
            link = f"https://raw.githubusercontent.com/{username}/{repo}/main/{file_path_posix}"
        
        # æ„å»ºæè¿°
        description = f"æœ¬æœŸç²¾é€‰ {news_count} æ¡é«˜è´¨é‡ç§‘æŠ€æ–°é—»"
        
        # ä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºå‘å¸ƒæ—¶é—´
        pub_date = datetime.fromtimestamp(file_path.stat().st_mtime)
        
        # ä½¿ç”¨æ–‡ä»¶è·¯å¾„ä½œä¸ºå”¯ä¸€guidï¼ˆPOSIXæ ¼å¼ï¼‰
        guid = file_path_posix
        
        return {
            'title': title,
            'link': link,
            'description': description,
            'date': file_date or pub_date,
            'pub_date': self._format_rfc822(pub_date),
            'guid': guid,
            'file_path': str(file_path),
            'news_count': news_count,
            'full_content': content  # æ·»åŠ å®Œæ•´Markdownå†…å®¹
        }
    
    def _build_rss_xml(self, file_infos: List[Dict]) -> str:
        """æ„å»ºRSS 2.0 XML"""
        now = datetime.utcnow()
        build_date = self._format_rfc822(now)
        
        # è·å–GitHubä»“åº“ä¿¡æ¯(ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶)
        repo_url = os.getenv('GITHUB_REPOSITORY', 'username/news')
        username, repo = repo_url.split('/') if '/' in repo_url else ('username', 'news')
        
        feed_url = f"https://{username}.github.io/{repo}/feed.xml"
        project_url = f"https://github.com/{username}/{repo}"
        
        # æ„å»ºitems XML
        items_xml = []
        for file_info in file_infos:
            items_xml.append(self._build_item_xml(file_info))
        
        rss = f"""<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
<channel>
    <title>ç§‘æŠ€æ–°é—»ç²¾é€‰</title>
    <link>{project_url}</link>
    <description>ç”± AI ç­›é€‰çš„é«˜è´¨é‡ç§‘æŠ€æ–°é—»èšåˆï¼Œæ¯6å°æ—¶è‡ªåŠ¨æ›´æ–°</description>
    <language>zh-CN</language>
    <lastBuildDate>{build_date}</lastBuildDate>
    <pubDate>{build_date}</pubDate>
    <atom:link href="{feed_url}" rel="self" type="application/rss+xml" />
    <image>
        <url>https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png</url>
        <title>ç§‘æŠ€æ–°é—»ç²¾é€‰</title>
        <link>{project_url}</link>
    </image>
{''.join(items_xml)}
</channel>
</rss>"""
        
        return rss
    
    def _build_item_xml(self, file_info: Dict) -> str:
        """æ„å»ºå•ä¸ªitem XMLï¼ˆæ”¯æŒä¸‰æ¿å—åˆ†ç±»ï¼‰"""
        title = escape(file_info.get('title', ''))
        link = file_info.get('link', '')
        description = escape(file_info.get('description', ''))
        pub_date = file_info.get('pub_date', '')
        guid = escape(file_info.get('guid', ''))

        # è·å–åˆ†ç±»ä¿¡æ¯ï¼ˆä»æ–°é—»åˆ—è¡¨ä¸­æå–ï¼Œé»˜è®¤ä¸ºç»¼åˆï¼‰
        category = file_info.get('category', 'ç»¼åˆæ–°é—»')

        # è·å–å®Œæ•´å†…å®¹å¹¶è½¬æ¢ä¸ºHTML
        full_content = file_info.get('full_content', '')

        # åˆ é™¤é‡å¤çš„è®¢é˜…éƒ¨åˆ†ï¼ˆä»## è®¢é˜…å¼€å§‹åˆ°æ–‡ä»¶ç»“æŸï¼‰
        subscription_pattern = r'##\s*ğŸ“®\s*è®¢é˜….*$'
        full_content = re.sub(subscription_pattern, '', full_content, flags=re.DOTALL)

        # æ›¿æ¢å ä½ç¬¦
        repo_url = os.getenv('GITHUB_REPOSITORY', 'username/news')
        username, repo = repo_url.split('/') if '/' in repo_url else ('username', 'news')
        full_content = full_content.replace('{username}', username)
        full_content = full_content.replace('{repo}', repo)

        # è½¬æ¢ä¸ºHTML
        if full_content:
            html_content = self._markdown_to_html(full_content)
            content_encoded = f"<![CDATA[{html_content}]]>"
        else:
            content_encoded = ""

        return f"""
    <item>
        <title>{title}</title>
        <link>{link}</link>
        <description>{description}</description>
        <pubDate>{pub_date}</pubDate>
        <guid>{guid}</guid>
        <category>{category}</category>
        <content:encoded>{content_encoded}</content:encoded>
    </item>"""
    
    def _format_rfc822(self, dt: datetime) -> str:
        """æ ¼å¼åŒ–ä¸ºRFC822æ—¥æœŸæ ¼å¼"""
        # ä½¿ç”¨è‹±æ–‡æœˆä»½ç¼©å†™
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        
        day_name = days[dt.weekday()]
        month_name = months[dt.month - 1]
        
        return f"{day_name}, {dt.day:02d} {month_name} {dt.year} {dt.hour:02d}:{dt.minute:02d}:{dt.second:02d} GMT"
