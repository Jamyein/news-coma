"""
RSSè®¢é˜…æ–‡ä»¶ç”Ÿæˆæ¨¡å—
è´Ÿè´£åŸºäºMarkdownæ–‡ä»¶ç”ŸæˆRSS feed.xmlæ–‡ä»¶
"""
import logging
import os
import re
from datetime import datetime

from xml.sax.saxutils import escape
from pathlib import Path

logger = logging.getLogger(__name__)


class RSSGenerator:
    """åŸºäºMarkdownæ–‡ä»¶çš„RSSè®¢é˜…æ–‡ä»¶ç”Ÿæˆå™¨"""
    
    def __init__(self, feed_path: str = "feed.xml", archive_dir: str = "archive", 
                 docs_dir: str = "docs", max_items: int = 50, use_smart_switch: bool = True):
        self.feed_path = Path(feed_path)
        self.archive_dir = Path(archive_dir)
        self.docs_dir = Path(docs_dir)
        self.max_items = max_items
        self.use_smart_switch = use_smart_switch
    
    def _markdown_to_html(self, markdown_text: str) -> str:
        """
        å°†Markdownæ–‡æœ¬è½¬æ¢ä¸ºHTML
        
        Args:
            markdown_text: Markdownæ ¼å¼çš„æ–‡æœ¬
            
        Returns:
            HTMLæ ¼å¼çš„æ–‡æœ¬
        """
        if not markdown_text:
            return ""
        
        html = markdown_text

        # 1. è½¬æ¢ä¸€çº§æ ‡é¢˜ (# â†’ <h1>)
        html = re.sub(r'^#\s+(.+?)$', r'<h1>\1</h1>', html, flags=re.MULTILINE)

        # 2. è½¬æ¢äºŒçº§æ ‡é¢˜ (## â†’ <h2>)
        html = re.sub(r'^##\s+(.+?)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)

        # 3. è½¬æ¢ä¸‰çº§æ ‡é¢˜ (### â†’ <h3>)
        html = re.sub(r'^###\s+(.+?)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
        
        # 2. è½¬æ¢ç²—ä½“ (** â†’ <strong>)
        html = re.sub(r'\*\*([^*]+?)\*\*', r'<strong>\1</strong>', html)
        
        # 4. è½¬æ¢å¼•ç”¨å— (> â†’ <blockquote>)
        def replace_quote(match):
            quote_content = match.group(1)
            return f'<blockquote>{quote_content}</blockquote>'
        html = re.sub(r'^>\s+(.+?)$', replace_quote, html, flags=re.MULTILINE)

        # 5. è½¬æ¢é“¾æ¥ ([æ–‡æœ¬](URL) â†’ <a>)
        def replace_link(match):
            link_text = match.group(1)
            url = match.group(2)
            return f'<a href="{url}">{link_text}</a>'
        html = re.sub(r'\[([^\]]+)\]\(([^\)]+)\)', replace_link, html)

        # 6. è½¬æ¢åˆ—è¡¨ (- â†’ <ul><li>)
        lines = html.split('\n')
        result_lines = []
        in_list = False
        list_items = []
        
        for line in lines:
            stripped = line.strip()
            list_match = re.match(r'^[-\*]\s+(.+)$', stripped)
            
            if list_match:
                if not in_list:
                    in_list = True
                    list_items = []
                item_text = list_match.group(1)
                list_items.append(f'<li>{item_text}</li>')
            else:
                if in_list:
                    result_lines.append('<ul>')
                    result_lines.extend(list_items)
                    result_lines.append('</ul>')
                    in_list = False
                    list_items = []
                result_lines.append(line)
        
        if in_list:
            result_lines.append('<ul>')
            result_lines.extend(list_items)
            result_lines.append('</ul>')
        
        html = '\n'.join(result_lines)

        # 7. è½¬æ¢åˆ†éš”çº¿ (--- â†’ <hr/>)
        html = re.sub(r'^---\s*$', '<hr/>', html, flags=re.MULTILINE)

        # 8. åŒ…è£¹æ®µè½
        lines = html.split('\n')
        result_lines = []
        current_para = []
        
        for line in lines:
            stripped = line.strip()
            
            if not stripped or (stripped.startswith('<') and stripped.endswith('>')):
                if current_para:
                    para_text = ' '.join(current_para)
                    if para_text:
                        result_lines.append(f'<p>{para_text}</p>')
                    current_para = []
                if stripped:
                    result_lines.append(line)
            else:
                current_para.append(stripped)
        
        if current_para:
            para_text = ' '.join(current_para)
            if para_text:
                result_lines.append(f'<p>{para_text}</p>')
        
        html = '\n'.join(result_lines)
        
        return html.strip()
    
    def generate(self) -> str:
        """
        åŸºäºMarkdownæ–‡ä»¶ç”ŸæˆRSS feed.xml
        
        Returns:
            ç”Ÿæˆçš„RSS XMLå­—ç¬¦ä¸²
        """
        # æ”¶é›†æ‰€æœ‰Markdownæ–‡ä»¶
        markdown_files = self._collect_markdown_files()
        
        # è§£ææ–‡ä»¶ä¿¡æ¯
        file_infos = []
        for file_path in markdown_files:
            try:
                file_info = self._parse_markdown_file(file_path)
                if file_info:
                    file_infos.append(file_info)
            except Exception as e:
                logger.warning(f"è§£æMarkdownæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æŒ‰æ—¥æœŸæ’åº(æœ€æ–°çš„åœ¨å‰)
        file_infos.sort(key=lambda x: x.get('date', datetime.min), reverse=True)
        
        # é™åˆ¶æ•°é‡
        file_infos = file_infos[:self.max_items]
        
        # ç”ŸæˆXML
        rss_xml = self._build_rss_xml(file_infos)
        
        # å†™å…¥æ–‡ä»¶
        self.feed_path.write_text(rss_xml, encoding='utf-8')
        # è®°å½•æ™ºèƒ½åˆ‡æ¢ç»Ÿè®¡ä¿¡æ¯
        if self.use_smart_switch:
            self._log_smart_switch_stats(file_infos)
        
        logger.info(f"å·²æ›´æ–°RSS feed: {self.feed_path} ({len(file_infos)} ä¸ªæ–‡ä»¶)")
        
        return rss_xml
    
    def get_required_source(self, now: datetime = None) -> str:
        """
        è·å–RSSç”Ÿæˆæ‰€éœ€çš„æ•°æ®æºç±»å‹ï¼ˆä¾›main.pyåœ¨ç”Ÿæˆå‰åè°ƒï¼‰
        
        é€»è¾‘ï¼š
        - å½“å¤©é¦–æ¬¡è¿è¡Œï¼ˆarchiveä¸å­˜åœ¨ï¼‰ï¼šè¿”å› 'archive'
        - å½“å¤©åç»­è¿è¡Œï¼ˆarchiveå·²å­˜åœ¨ï¼‰ï¼šè¿”å› 'latest'
        
        Args:
            now: å¯é€‰ï¼ŒæŒ‡å®šæ£€æµ‹æ—¶é—´ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´
            
        Returns:
            'archive' æˆ– 'latest'
        """
        if now is None:
            now = datetime.now()
        
        date = now.date()
        archive_filename = date.strftime("%Y-%m-%d") + ".md"
        archive_path = self.archive_dir / archive_filename
        
        if archive_path.exists():
            return 'latest'
        else:
            return 'archive'
    
    def _log_smart_switch_stats(self, file_infos: list[dict]):
        """è®°å½•æ™ºèƒ½åˆ‡æ¢çš„ç»Ÿè®¡ä¿¡æ¯"""
        try:
            latest_count = 0
            archive_count = 0
            
            for file_info in file_infos:
                file_path = file_info.get('file_path', '')
                if file_path.endswith('latest.md'):
                    latest_count += 1
                else:
                    archive_count += 1
            
            logger.info(f"æ™ºèƒ½åˆ‡æ¢ç»Ÿè®¡: {archive_count}ä¸ªarchiveæ–‡ä»¶, {latest_count}ä¸ªlatestæ–‡ä»¶")
            
            # è®°å½•å…·ä½“æ–‡ä»¶ä¿¡æ¯
            if latest_count > 0:
                logger.info("æœ¬æ¬¡ä½¿ç”¨äº†latest.mdæ–‡ä»¶ï¼ˆæœªæ‰¾åˆ°å¯¹åº”archiveæ–‡ä»¶ï¼‰")
            
        except Exception as e:
            logger.error(f"è®°å½•æ™ºèƒ½åˆ‡æ¢ç»Ÿè®¡å¤±è´¥: {e}")
    
    def _collect_markdown_files(self) -> list[Path]:
        """æ”¶é›†archiveå’Œdocsç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶ï¼Œæ”¯æŒæ™ºèƒ½åˆ‡æ¢é€»è¾‘"""
        markdown_files = []
        
        # æ”¶é›†archiveç›®å½•ä¸­çš„æ–‡ä»¶
        if self.archive_dir.exists():
            for file_path in self.archive_dir.glob("*.md"):
                markdown_files.append(file_path)
        
        # å¤„ç†latest.mdæ–‡ä»¶ï¼ˆæ™ºèƒ½åˆ‡æ¢é€»è¾‘ï¼‰
        if self.docs_dir.exists():
            latest_file = self.docs_dir / "latest.md"
            
            if latest_file.exists():
                if self.use_smart_switch:
                    # æ™ºèƒ½åˆ‡æ¢é€»è¾‘ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”æ—¥æœŸçš„archiveæ–‡ä»¶
                    try:
                        # ä»latest.mdä¸­æå–æ—¥æœŸ
                        latest_date = self._extract_date_from_latest(latest_file)
                        if latest_date:
                            # æ„å»ºå¯¹åº”çš„archiveæ–‡ä»¶å
                            archive_filename = latest_date.strftime("%Y-%m-%d") + ".md"
                            archive_file = self.archive_dir / archive_filename
                            
                            if archive_file.exists():
                                # å¦‚æœarchiveæ–‡ä»¶å­˜åœ¨ï¼Œä½¿ç”¨latest.mdï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰
                                logger.info(f"æ™ºèƒ½åˆ‡æ¢ï¼šæ£€æµ‹åˆ°archiveæ–‡ä»¶ {archive_filename} å·²å­˜åœ¨ï¼Œä½¿ç”¨latest.mdï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰")
                                markdown_files.append(latest_file)
                            else:
                                # å¦‚æœarchiveæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨archiveæ–‡ä»¶ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
                                logger.info(f"æ™ºèƒ½åˆ‡æ¢ï¼šæœªæ‰¾åˆ°å¯¹åº”archiveæ–‡ä»¶ï¼Œé¦–æ¬¡è¿è¡Œï¼Œä½¿ç”¨archiveæ–‡ä»¶")
                                if archive_file not in markdown_files:
                                    markdown_files.append(archive_file)
                        else:
                            # æ— æ³•ä»latest.mdæå–æ—¥æœŸï¼Œä½¿ç”¨latest.md
                            logger.warning(f"æ— æ³•ä»latest.mdæå–æ—¥æœŸï¼Œä½¿ç”¨latest.md")
                            markdown_files.append(latest_file)
                    except Exception as e:
                        # æ™ºèƒ½åˆ‡æ¢å¤±è´¥ï¼Œä½¿ç”¨latest.md
                        logger.error(f"æ™ºèƒ½åˆ‡æ¢å¤±è´¥: {e}ï¼Œä½¿ç”¨latest.md")
                        markdown_files.append(latest_file)
                else:
                    # ä¸ä½¿ç”¨æ™ºèƒ½åˆ‡æ¢ï¼Œç›´æ¥æ·»åŠ latest.md
                    markdown_files.append(latest_file)
        
        # æ—¥å¿—è®°å½•
        if self.use_smart_switch:
            logger.info(f"æ™ºèƒ½åˆ‡æ¢æ¨¡å¼ï¼šæ‰¾åˆ° {len(markdown_files)} ä¸ªMarkdownæ–‡ä»¶")
        else:
            logger.info(f"ä¼ ç»Ÿæ¨¡å¼ï¼šæ‰¾åˆ° {len(markdown_files)} ä¸ªMarkdownæ–‡ä»¶")
            
        return markdown_files
    
    def _extract_date_from_latest(self, latest_file: Path) -> datetime:
        """ä»latest.mdæ–‡ä»¶ä¸­æå–æ—¥æœŸ"""
        try:
            content = latest_file.read_text(encoding='utf-8')
            
            # æ¨¡å¼1ï¼šä»"æ›´æ–°æ—¶é—´:"ä¸­æå–æ—¥æœŸ
            date_match = re.search(r'æ›´æ–°æ—¶é—´:\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥', content)
            if date_match:
                year, month, day = int(date_match.group(1)), int(date_match.group(2)), int(date_match.group(3))
                return datetime(year, month, day)
            
            # æ¨¡å¼2ï¼šä»æ ‡é¢˜ä¸­æå–æ—¥æœŸ
            title_match = re.search(r'#\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥', content)
            if title_match:
                year, month, day = int(title_match.group(1)), int(title_match.group(2)), int(title_match.group(3))
                return datetime(year, month, day)
            
            # æ¨¡å¼3ï¼šä»æ–‡ä»¶åä¸­å°è¯•æå–ï¼ˆå¦‚æœä½¿ç”¨æ—¥æœŸæ ¼å¼å‘½åçš„è½¯é“¾æ¥ï¼‰
            filename_match = re.match(r'(\d{4})-(\d{2})-(\d{2})\.md$', latest_file.name)
            if filename_match:
                year, month, day = int(filename_match.group(1)), int(filename_match.group(2)), int(filename_match.group(3))
                return datetime(year, month, day)
                
            logger.warning(f"æ— æ³•ä»latest.mdä¸­æå–æ—¥æœŸ: {latest_file}")
            return None
            
        except Exception as e:
            logger.error(f"ä»latest.mdæå–æ—¥æœŸå¤±è´¥: {e}")
            return None
    
    def _extract_datetime_from_latest(self, content: str) -> datetime:
        """ä»latest.mdå†…å®¹ä¸­æå–å®Œæ•´çš„æ—¥æœŸæ—¶é—´ï¼ˆå«æ—¶åˆ†ï¼‰
        
        Args:
            content: latest.mdçš„æ–‡ä»¶å†…å®¹
            
        Returns:
            åŒ…å«å¹´æœˆæ—¥æ—¶åˆ†ä¿¡æ¯çš„datetimeå¯¹è±¡ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            # æ¨¡å¼ï¼šä»"æ›´æ–°æ—¶é—´:"ä¸­æå–å®Œæ•´æ—¥æœŸæ—¶é—´
            # åŒ¹é…æ ¼å¼ï¼š2026å¹´02æœˆ05æ—¥ 20:46
            match = re.search(r'æ›´æ–°æ—¶é—´:\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥\s*(\d{2}):(\d{2})', content)
            if match:
                year, month, day, hour, minute = map(int, match.groups())
                return datetime(year, month, day, hour, minute)
            
            # å¤‡é€‰ï¼šä»…æå–æ—¥æœŸï¼ˆä¸å«æ—¶åˆ†ï¼‰
            match = re.search(r'æ›´æ–°æ—¶é—´:\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥', content)
            if match:
                year, month, day = map(int, match.groups())
                return datetime(year, month, day)
                
            return None
            
        except Exception as e:
            logger.error(f"ä»latest.mdæå–å®Œæ•´æ—¥æœŸæ—¶é—´å¤±è´¥: {e}")
            return None
    
    def _parse_markdown_file(self, file_path: Path) -> dict:
        """è§£æMarkdownæ–‡ä»¶ï¼Œæå–ä¿¡æ¯"""
        if not file_path.exists():
            return None
        
        content = file_path.read_text(encoding='utf-8')
        
        # æå–æ—¥æœŸï¼ˆä½¿ç”¨å¢å¼ºçš„æ—¥æœŸæå–é€»è¾‘ï¼‰
        file_date = self._extract_date_from_file(file_path, content)
        
        # æå–æ–°é—»æ•°é‡
        news_count = 0
        count_match = re.search(r'æœ¬æœŸç²¾é€‰\s*\*\*(\d+)\*\*\s*æ¡', content)
        if count_match:
            news_count = int(count_match.group(1))
        
        # æ„å»ºæ ‡é¢˜
        if file_path.name == "latest.md":
            # latest.mdï¼šæ ‡é¢˜åŒ…å«æ—¶åˆ†ä¿¡æ¯ï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰
            pub_time = self._extract_datetime_from_latest(content)
            if pub_time:
                title = f"{pub_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} æ–°é—»æ±‡æ€»"
            elif file_date:
                title = f"{file_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} æ–°é—»æ±‡æ€»"
            else:
                title = f"{file_path.stem} æ–°é—»æ±‡æ€»"
        elif file_date:
            # archiveæ–‡ä»¶ï¼šæ ‡é¢˜åªæ˜¾ç¤ºæ—¥æœŸ
            title = f"{file_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} æ–°é—»æ±‡æ€»"
        else:
            title = f"{file_path.stem} æ–°é—»æ±‡æ€»"
        
        # æ„å»ºé“¾æ¥
        repo_url = os.getenv('GITHUB_REPOSITORY', 'username/news')
        username, repo = repo_url.split('/') if '/' in repo_url else ('username', 'news')
        
        # å°†Windowsè·¯å¾„è½¬æ¢ä¸ºPOSIXè·¯å¾„ç”¨äºURL
        file_path_posix = str(file_path).replace('\\', '/')
        
        if file_path.name == "latest.md":
            # latest.md ä½¿ç”¨GitHub Pages URL
            link = f"https://{username}.github.io/{repo}/"
        else:
            # å½’æ¡£æ–‡ä»¶ä½¿ç”¨GitHub raw URL
            link = f"https://raw.githubusercontent.com/{username}/{repo}/main/{file_path_posix}"
        
        # æ„å»ºæè¿°
        description = f"æœ¬æœŸç²¾é€‰ {news_count} æ¡é«˜è´¨é‡ç§‘æŠ€æ–°é—»"
        
        # ä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºå‘å¸ƒæ—¶é—´
        pub_date = datetime.fromtimestamp(file_path.stat().st_mtime)
        
        # ä½¿ç”¨æ–‡ä»¶è·¯å¾„ä½œä¸ºå”¯ä¸€guidï¼ˆPOSIXæ ¼å¼ï¼‰
        guid = file_path_posix
        
        return {
            'title': title,
            'link': link,
            'description': description,
            'date': file_date or pub_date,
            'pub_date': self._format_rfc822(pub_date),
            'guid': guid,
            'file_path': str(file_path),
            'news_count': news_count,
            'full_content': content  # æ·»åŠ å®Œæ•´Markdownå†…å®¹
        }
    
    def _extract_date_from_file(self, file_path: Path, content: str) -> datetime:
        """ä»æ–‡ä»¶å†…å®¹ä¸­æå–æ—¥æœŸ"""
        try:
            if file_path.name == "latest.md":
                # latest.md: å°è¯•å¤šç§æ¨¡å¼æå–æ—¥æœŸ
                patterns = [
                    # å®Œæ•´æ—¥æœŸæ—¶é—´
                    (r'æ›´æ–°æ—¶é—´:\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥\s*(\d{2}):(\d{2})', 5),
                    # ä»…æ—¥æœŸ
                    (r'æ›´æ–°æ—¶é—´:\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥', 3),
                    (r'#\s*(\d{4})å¹´(\d{2})æœˆ(\d{2})æ—¥', 3),
                ]
                
                for pattern, group_count in patterns:
                    match = re.search(pattern, content)
                    if match:
                        nums = [int(match.group(i)) for i in range(1, group_count + 1)]
                        if group_count == 5:
                            return datetime(*nums)
                        return datetime(*nums)
                
                logger.warning(f"æ— æ³•ä»latest.mdæå–æ—¥æœŸ: {file_path}")
                
            else:
                # å½’æ¡£æ–‡ä»¶: ä»æ–‡ä»¶åæå–æ—¥æœŸ (YYYY-MM-DD.md)
                match = re.match(r'(\d{4})-(\d{2})-(\d{2})\.md$', file_path.name)
                if match:
                    return datetime(*[int(x) for x in match.groups()])
            
            return None
            
        except Exception as e:
            logger.error(f"ä»æ–‡ä»¶æå–æ—¥æœŸå¤±è´¥ {file_path}: {e}")
            return None
    
    def _build_rss_xml(self, file_infos: list[dict]) -> str:
        """æ„å»ºRSS 2.0 XML"""
        now = datetime.utcnow()
        build_date = self._format_rfc822(now)
        
        # è·å–GitHubä»“åº“ä¿¡æ¯(ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶)
        repo_url = os.getenv('GITHUB_REPOSITORY', 'username/news')
        username, repo = repo_url.split('/') if '/' in repo_url else ('username', 'news')
        
        feed_url = f"https://{username}.github.io/{repo}/feed.xml"
        project_url = f"https://github.com/{username}/{repo}"
        
        # æ„å»ºitems XML
        items_xml = []
        for file_info in file_infos:
            items_xml.append(self._build_item_xml(file_info))
        
        rss = f"""<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
<channel>
    <title>ç§‘æŠ€æ–°é—»ç²¾é€‰</title>
    <link>{project_url}</link>
    <description>ç”± AI ç­›é€‰çš„é«˜è´¨é‡ç§‘æŠ€æ–°é—»èšåˆï¼Œæ¯6å°æ—¶è‡ªåŠ¨æ›´æ–°</description>
    <language>zh-CN</language>
    <lastBuildDate>{build_date}</lastBuildDate>
    <pubDate>{build_date}</pubDate>
    <atom:link href="{feed_url}" rel="self" type="application/rss+xml" />
    <image>
        <url>https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png</url>
        <title>ç§‘æŠ€æ–°é—»ç²¾é€‰</title>
        <link>{project_url}</link>
    </image>
{''.join(items_xml)}
</channel>
</rss>"""
        
        return rss
    
    def _build_item_xml(self, file_info: dict) -> str:
        """æ„å»ºå•ä¸ªitem XMLï¼ˆæ”¯æŒä¸‰æ¿å—åˆ†ç±»ï¼‰"""
        title = escape(file_info.get('title', ''))
        link = file_info.get('link', '')
        description = escape(file_info.get('description', ''))
        pub_date = file_info.get('pub_date', '')
        guid = escape(file_info.get('guid', ''))

        # è·å–åˆ†ç±»ä¿¡æ¯ï¼ˆä»æ–°é—»åˆ—è¡¨ä¸­æå–ï¼Œé»˜è®¤ä¸ºç»¼åˆï¼‰
        category = file_info.get('category', 'ç»¼åˆæ–°é—»')

        # è·å–å®Œæ•´å†…å®¹å¹¶è½¬æ¢ä¸ºHTML
        full_content = file_info.get('full_content', '')

        # åˆ é™¤é‡å¤çš„è®¢é˜…éƒ¨åˆ†ï¼ˆä»## è®¢é˜…å¼€å§‹åˆ°æ–‡ä»¶ç»“æŸï¼‰
        subscription_pattern = r'##\s*ğŸ“®\s*è®¢é˜….*$'
        full_content = re.sub(subscription_pattern, '', full_content, flags=re.DOTALL)

        # æ›¿æ¢å ä½ç¬¦
        repo_url = os.getenv('GITHUB_REPOSITORY', 'username/news')
        username, repo = repo_url.split('/') if '/' in repo_url else ('username', 'news')
        full_content = full_content.replace('{username}', username)
        full_content = full_content.replace('{repo}', repo)

        # è½¬æ¢ä¸ºHTML
        if full_content:
            html_content = self._markdown_to_html(full_content)
            content_encoded = f"<![CDATA[{html_content}]]>"
        else:
            content_encoded = ""

        return f"""
    <item>
        <title>{title}</title>
        <link>{link}</link>
        <description>{description}</description>
        <pubDate>{pub_date}</pubDate>
        <guid>{guid}</guid>
        <category>{category}</category>
        <content:encoded>{content_encoded}</content:encoded>
    </item>"""
    
    def _format_rfc822(self, dt: datetime) -> str:
        """æ ¼å¼åŒ–ä¸ºRFC822æ—¥æœŸæ ¼å¼"""
        # ä½¿ç”¨è‹±æ–‡æœˆä»½ç¼©å†™
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        
        day_name = days[dt.weekday()]
        month_name = months[dt.month - 1]
        
        return f"{day_name}, {dt.day:02d} {month_name} {dt.year} {dt.hour:02d}:{dt.minute:02d}:{dt.second:02d} GMT"
