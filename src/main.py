"""
ä¸»ç¨‹åºå…¥å£
åè°ƒå„æ¨¡å—å®ŒæˆRSSæ–°é—»èšåˆæµç¨‹
"""
import os
import sys

# Add project root to sys.path to allow imports from src package
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import logging
import asyncio
from datetime import datetime
from typing import List

from src.config import Config
from src.models import NewsItem
from src.rss_fetcher import RSSFetcher
from src.AIScorer import AIScorer
from src.markdown_generator import MarkdownGenerator
from src.rss_generator import RSSGenerator
from src.history_manager import HistoryManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)


class RSSAggregator:
    """RSSæ–°é—»èšåˆå™¨ä¸»ç±»"""
    
    def __init__(self):
        self.config = Config()
        self.history = HistoryManager()
        self.fetcher = None
        self.scorer = None
        self.markdown_gen = None
        self.rss_gen = None
    
    async def run(self) -> bool:
        """
        æ‰§è¡Œå®Œæ•´çš„æ–°é—»èšåˆæµç¨‹ (å¸¦è¯¦ç»†æŒ‡æ ‡æ”¶é›†)
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        start_time = datetime.now()
        logger.info("=" * 50)
        logger.info(f"ğŸš€ RSSæ–°é—»èšåˆå¼€å§‹ - {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 50)
        
        # åˆå§‹åŒ–è¿è¡ŒæŒ‡æ ‡
        run_metrics = {
            "api_calls": 0,
        }
        
        try:
            # 1. åˆå§‹åŒ–å„æ¨¡å—
            self._init_modules()
            
            # 2. è·å–RSSæ–°é—»
            news_items = self._fetch_news()
            if not news_items:
                logger.warning("æœªè·å–åˆ°ä»»ä½•æ–°é—»")
                return False

            # 3. AIè¯„åˆ†å’Œç¿»è¯‘ (é›†æˆç¼“å­˜)
            scored_items = await self._score_news(news_items)
            
            # 4. ç­›é€‰Top N
            top_items = self._select_top_news(scored_items)
            
            # 5. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
            self._generate_outputs(top_items)
            
            # è®¡ç®—æŒç»­æ—¶é—´
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            run_metrics["duration_seconds"] = duration
            
            # è®°å½•APIè°ƒç”¨æ¬¡æ•° (ä»AIScorerè·å–)
            run_metrics["api_calls"] = self.scorer.get_api_call_count()
            
            # 6. æ›´æ–°å†å²ç»Ÿè®¡ (å¸¦è¯¦ç»†æŒ‡æ ‡)
            self._update_stats(start_time, news_items, top_items, run_metrics)
            
            # é‡ç½®APIè°ƒç”¨è®¡æ•°
            self.scorer.reset_api_call_count()
            
            logger.info("=" * 50)
            logger.info(f"âœ… RSSæ–°é—»èšåˆå®Œæˆ - è€—æ—¶: {duration:.1f}ç§’")
            logger.info(f"ğŸ“Š æœ¬æ¬¡å¤„ç†: {len(news_items)}æ¡ â†’ ç²¾é€‰: {len(top_items)}æ¡")
            logger.info("=" * 50)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return False
    
    def _init_modules(self):
        """åˆå§‹åŒ–å„æ¨¡å—"""
        logger.info("åˆå§‹åŒ–æ¨¡å—...")
        
        self.fetcher = RSSFetcher(
            sources=self.config.rss_sources,
            output_config=self.config.output_config,
            filter_config=self.config.filter_config
        )
        
        self.scorer = AIScorer(config=self.config.ai_config)
        
        self.markdown_gen = MarkdownGenerator(
            output_dir="docs",
            archive_dir="archive"
        )
        
        self.rss_gen = RSSGenerator(
            feed_path="feed.xml",
            archive_dir="archive",
            docs_dir="docs",
            max_items=self.config.output_config.max_feed_items,
            use_smart_switch=self.config.output_config.use_smart_switch
        )
        
        logger.info(f"âœ“ å·²åŠ è½½ {len(self.config.rss_sources)} ä¸ªRSSæº")
        ai_config = self.config.ai_config
        current_provider = ai_config.provider
        provider_config = ai_config.providers_config[current_provider]
        logger.info(f"âœ“ AIæ¨¡å‹: {current_provider} ({provider_config.model})")
    
    def _fetch_news(self) -> List[NewsItem]:
        """
        è·å–æ–°é—»ï¼ˆæ”¯æŒåŸºäºæ—¶é—´èŠ‚ç‚¹çš„å¢é‡è·å–ï¼‰
        """
        logger.info("ğŸ“¡ å¼€å§‹è·å–RSSæ–°é—»...")
        
        all_items = []
        source_stats = {}
        
        for source in self.config.rss_sources:
            if not source.enabled:
                continue
            
            # è·å–è¯¥æºçš„æœ€åè·å–æ—¶é—´
            last_fetch = self.history.get_source_last_fetch(source.name)
            
            # å¦‚æœè¯¥æºæ²¡æœ‰è®°å½•ï¼Œå°è¯•ä½¿ç”¨fallback
            if not last_fetch:
                last_fetch = self.history.get_fallback_last_fetch()
                if last_fetch:
                    logger.info(f"â° {source.name} ä½¿ç”¨å…¨å±€fallbackæ—¶é—´: {last_fetch}")
            
            try:
                # è·å–è¯¥æºçš„æ–°é—»ï¼ˆä¼ å…¥last_fetchå®ç°å¢é‡è·å–ï¼‰
                items = self.fetcher._fetch_single(source, last_fetch)
                all_items.extend(items)
                source_stats[source.name] = len(items)
                
                # æ›´æ–°è¯¥æºçš„æœ€åè·å–æ—¶é—´ï¼ˆä½¿ç”¨å½“å‰æ—¶é—´ï¼‰
                self.history.update_source_last_fetch(source.name, datetime.now())
                
                if last_fetch:
                    logger.info(
                        f"âœ“ {source.name}: å¢é‡è·å– {len(items)} æ¡ "
                        f"(ä¸Šæ¬¡: {last_fetch.strftime('%m-%d %H:%M')})"
                    )
                else:
                    logger.info(f"âœ“ {source.name}: å…¨é‡è·å– {len(items)} æ¡")
                    
            except Exception as e:
                logger.error(f"âŒ è·å– {source.name} å¤±è´¥: {e}")
                # å¤±è´¥æ—¶ä¸æ›´æ–°æ—¶é—´æˆ³ï¼Œä¸‹æ¬¡ä¼šé‡è¯•
                continue
        
        logger.info(f"ğŸ“Š æ€»è®¡: è·å– {len(all_items)} æ¡")
        logger.info(f"ğŸ“Š å„æºç»Ÿè®¡: {source_stats}")
        
        return all_items
    
    async def _score_news(self, items: List[NewsItem]) -> List[NewsItem]:
        """AIè¯„åˆ†"""
        logger.info(f"ğŸ¤– å¼€å§‹AIè¯„åˆ†(å…± {len(items)} æ¡)...")

        # å¯¹æ‰€æœ‰é¡¹ç›®è¿›è¡Œè¯„åˆ†
        scored_items = await self.scorer.score_all(items)

        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„
        threshold = self.config.filter_config.min_score_threshold
        filtered = [item for item in scored_items if (item.ai_score or 0) >= threshold]

        logger.info(f"âœ“ è¯„åˆ†å®Œæˆ: {len(scored_items)}æ¡ï¼Œâ‰¥{threshold}åˆ†: {len(filtered)}æ¡")

        return filtered
    
    def _select_top_news(self, items: List[NewsItem]) -> List[NewsItem]:
        """é€‰æ‹©Top Næ–°é—»ï¼ˆæŒ‰ä¸‰æ¿å—4:3:3å›ºå®šæ¯”ä¾‹åˆ†é…ï¼‰"""
        if not items:
            return []

        # æŒ‰ ai_category åˆ†ç»„
        finance_items = [item for item in items if item.ai_category == "è´¢ç»"]
        tech_items = [item for item in items if item.ai_category == "ç§‘æŠ€"]
        politics_items = [item for item in items if item.ai_category == "ç¤¾ä¼šæ”¿æ²»"]
        
        # æœªåˆ†ç±»æ–°é—»å•ç‹¬å¤„ç†
        uncategorized_items = [item for item in items if item.ai_category not in ["è´¢ç»", "ç§‘æŠ€", "ç¤¾ä¼šæ”¿æ²»"]]

        # å›ºå®šæ€»æ•°ï¼š30æ¡ï¼ˆæ ¹æ®é…ç½®ï¼‰
        max_count = self.config.output_config.max_news_count  # ä»é…ç½®è¯»å–ï¼Œé»˜è®¤ä¸º30
        
        # å›ºå®šæ¯”ä¾‹åˆ†é…ï¼šè´¢ç»40%ï¼Œç§‘æŠ€30%ï¼Œç¤¾ä¼šæ”¿æ²»30%
        target_finance_count = int(max_count * self.config.ai_config.category_quota_finance)  # 12æ¡
        target_tech_count = int(max_count * self.config.ai_config.category_quota_tech)        # 9æ¡
        target_politics_count = int(max_count * self.config.ai_config.category_quota_politics)  # 9æ¡
        
        # å®é™…å¯é€‰å–æ•°é‡ï¼ˆä¸èƒ½è¶…è¿‡å®é™…å¯ç”¨æ•°é‡ï¼‰
        actual_finance_count = min(target_finance_count, len(finance_items))
        actual_tech_count = min(target_tech_count, len(tech_items))
        actual_politics_count = min(target_politics_count, len(politics_items))
        
        # è®¡ç®—å‰©ä½™é…é¢
        remaining_quota = max_count - (actual_finance_count + actual_tech_count + actual_politics_count)
        
        # å¦‚æœæŸæ¿å—æ–°é—»ä¸è¶³ï¼ŒæŒ‰ä¼˜å…ˆçº§é‡æ–°åˆ†é…é…é¢
        # ä¼˜å…ˆçº§ï¼šè´¢ç» > ç§‘æŠ€ > ç¤¾ä¼šæ”¿æ²» > æœªåˆ†ç±»
        if remaining_quota > 0:
            # é¦–å…ˆå°è¯•è¡¥å……è´¢ç»
            if actual_finance_count < target_finance_count:
                can_add = min(remaining_quota, target_finance_count - actual_finance_count)
                actual_finance_count += can_add
                remaining_quota -= can_add
            
            # ç„¶åå°è¯•è¡¥å……ç§‘æŠ€
            if remaining_quota > 0 and actual_tech_count < target_tech_count:
                can_add = min(remaining_quota, target_tech_count - actual_tech_count)
                actual_tech_count += can_add
                remaining_quota -= can_add
            
            # ç„¶åå°è¯•è¡¥å……ç¤¾ä¼šæ”¿æ²»
            if remaining_quota > 0 and actual_politics_count < target_politics_count:
                can_add = min(remaining_quota, target_politics_count - actual_politics_count)
                actual_politics_count += can_add
                remaining_quota -= can_add
            
            # æœ€åç”¨æœªåˆ†ç±»æ–°é—»å¡«å……å‰©ä½™é…é¢
            if remaining_quota > 0 and uncategorized_items:
                # ä»æœªåˆ†ç±»æ–°é—»ä¸­é€‰å–è¯„åˆ†æœ€é«˜çš„
                uncategorized_sorted = sorted(uncategorized_items, key=lambda x: (x.ai_score or 0, x.published_at), reverse=True)
                extra_from_uncategorized = min(remaining_quota, len(uncategorized_sorted))
                # å°†è¿™äº›æœªåˆ†ç±»æ–°é—»æ ‡è®°ä¸º"æœªåˆ†ç±»"æ¿å—
                for item in uncategorized_sorted[:extra_from_uncategorized]:
                    item.ai_category = "æœªåˆ†ç±»"
                uncategorized_selected = uncategorized_sorted[:extra_from_uncategorized]
                remaining_quota -= extra_from_uncategorized
            else:
                uncategorized_selected = []

        # å„è‡ªæ¿å—å†…æŒ‰AIè¯„åˆ†æ’åºå¹¶é€‰å–
        def sort_by_score(item_list):
            return sorted(item_list, key=lambda x: (x.ai_score or 0, x.published_at), reverse=True)

        selected_finance = sort_by_score(finance_items)[:actual_finance_count]
        selected_tech = sort_by_score(tech_items)[:actual_tech_count]
        selected_politics = sort_by_score(politics_items)[:actual_politics_count]
        
        # åˆå¹¶æ‰€æœ‰é€‰ä¸­æ–°é—»
        if 'uncategorized_selected' in locals():
            top_items = selected_finance + selected_tech + selected_politics + uncategorized_selected
        else:
            top_items = selected_finance + selected_tech + selected_politics

        # è®°å½•å„æ¿å—é€‰å–æƒ…å†µ
        logger.info(f"ğŸ“Š ä¸‰æ¿å—é€‰å–: è´¢ç» {len(selected_finance)}/{target_finance_count}æ¡ | ç§‘æŠ€ {len(selected_tech)}/{target_tech_count}æ¡ | ç¤¾ä¼šæ”¿æ²» {len(selected_politics)}/{target_politics_count}æ¡")
        if 'uncategorized_selected' in locals() and uncategorized_selected:
            logger.info(f"ğŸ“Š è¡¥å……æœªåˆ†ç±»æ–°é—»: {len(uncategorized_selected)}æ¡")
        logger.info(f"ğŸ“‹ ä» {len(items)} æ¡ä¸­ç²¾é€‰ Top {len(top_items)} æ¡æ–°é—» (ç›®æ ‡: {max_count}æ¡)")

        return top_items
    
    def _generate_outputs(self, items: List[NewsItem]):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        logger.info("ğŸ“ ç”Ÿæˆè¾“å‡ºæ–‡ä»¶...")
        
        now = datetime.now()
        
        # ç”ŸæˆMarkdown
        latest_path, archive_path = self.markdown_gen.generate(items, now)
        logger.info(f"âœ“ Markdown: {latest_path}")
        
        # ç”ŸæˆRSS
        self.rss_gen.generate()
        logger.info(f"âœ“ RSS feed: feed.xml")
    
    def _update_stats(self, run_time: datetime, all_items: List[NewsItem], 
                      selected_items: List[NewsItem],
                      run_metrics: dict = None):
        """æ›´æ–°ç»Ÿè®¡æ•°æ® (æ‰©å±•æ”¯æŒè¯¦ç»†è¿è¡ŒæŒ‡æ ‡)"""
        # æºç»Ÿè®¡
        source_stats = {}
        for item in all_items:
            source_stats[item.source] = source_stats.get(item.source, 0) + 1
        
        # è®¡ç®—å¹³å‡è¯„åˆ†
        avg_score = 0
        if selected_items:
            scores = [item.ai_score for item in selected_items if item.ai_score is not None]
            if scores:
                avg_score = sum(scores) / len(scores)
        
        # å‡†å¤‡è¯¦ç»†æŒ‡æ ‡
        metrics = run_metrics or {}
        metrics['avg_score'] = avg_score
        
        # æ›´æ–°å†å² (å¸¦è¯¦ç»†æŒ‡æ ‡)
        self.history.update_stats(run_time, len(all_items), source_stats, **metrics)
        
        # æ›´æ–°æºé€‰ä¸­ç»Ÿè®¡
        for item in selected_items:
            self.history.update_source_selected(item.source, 1)
        
        # ä¿å­˜
        self.history.save()
        
        # è¾“å‡ºç»Ÿè®¡
        stats = self.history.get_stats()
        logger.info(f"ğŸ“ˆ æ€»è¿è¡Œæ¬¡æ•°: {stats['total_runs']}")
        logger.info(f"ğŸ“ˆ æ€»å¤„ç†æ–°é—»: {stats['total_news_processed']}")
        logger.info(f"ğŸ“ˆ å¹³å‡æ¯æœŸ: {stats['avg_news_per_run']}")

        # è¾“å‡ºæ€§èƒ½æŠ¥å‘Š
        report = self.history.get_performance_report()
        if 'recent_runs' in report:
            logger.info("ğŸ“Š æ€§èƒ½æŠ¥å‘Š(æœ€è¿‘10æ¬¡å¹³å‡):")
            logger.info(f"   APIè°ƒç”¨: {report['avg_api_calls_per_run']:.1f} æ¬¡/è¿è¡Œ")
            logger.info(f"   å¹³å‡æ—¶é•¿: {report['avg_duration_seconds']:.1f} ç§’")


async def main():
    """ä¸»å…¥å£å‡½æ•°"""
    # åˆ›å»ºèšåˆå™¨å¹¶è¿è¡Œ
    # API key validation is now handled in Config class based on selected provider
    aggregator = RSSAggregator()
    success = await aggregator.run()
    
    if not success:
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
